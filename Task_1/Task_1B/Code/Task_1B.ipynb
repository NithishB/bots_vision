{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1B: Fruit classification with a CNN\n",
    "\n",
    "This notebook will serve as implementation of the API that you have created in your \"Code\" folder. You will write functions in the \"py\" files and use them here.\n",
    "\n",
    "We will be using \"Fruits\" dataset present in PyTorch and train a convolutional neural network (CNN) to classify digits.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is expected from this notebook?\n",
    "\n",
    "This notebook should be used to present your work. You should explain wherever necessary (but also not too much) about what you did and why you did it. You should explain things like hyper parameter settings (even if it was provided before hand to you by us), training performance and testing performance of the model. You should reason why your model is working fine and not overfitting.\n",
    "\n",
    "Since numbers don't are an argot, you should also use visualizations wherever possible. You can visualize things like **loss curve**, show **confusion matrix** and since this is a CNN you can also consider **advance techniques like gradcam**, etc. \n",
    "\n",
    "You can also use techniques that allow for faster training, assuage problems involving vanishing and exploding gradients. \n",
    "\n",
    "Finally, you can show some manual verifications by displaying and making predictions on random test examples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Absolutely required items?\n",
    "\n",
    "1. First of all, import the libraries and the dataset. Divide the dataset into test and train.\n",
    "2. Next, show dataset samples and distribution of different type of data. For example, in case of \"Fruits Dataset\" you can show some random images and their labels. Also, show distribution of each class of images.\n",
    "3. Next, perform required transformations (also **data augmentation**) on \"Fruits dataset\" (normalization, resizing, grayscaling, if required, etc.) using torchvision transforms.\n",
    "4. Create required dataloaders with PyTorch and use the module dataset we created to load data in mini-batches.\n",
    "5. Train the model, show loss and accuracy at each step of operation.\n",
    "6. Plot the **loss curve for both train and validation phase**.\n",
    "7. Pick some manual random images (probably 7-10) from test dataset and predict their values showing **expected and actual result**. \n",
    "\n",
    "**NOTE: ** \n",
    "1. You may or may not choose to delete these instruction cells after completion of the notebook.\n",
    "2. Keep the outputs of the cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading dataframes using dataset module \n",
    "df, df_train, df_test = dataset.create_and_load_meta_csv_df(dataset_path='../Data/fruits/', destination_path='../Data/', randomize=True, split=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using dataframes, pytorch and torchvision to transform data. Also, use dataloaders for batching, shuffling, etc.  \n",
    "data_transforms = {\n",
    "    'train': [],\n",
    "    'val': []\n",
    "}\n",
    "\n",
    "image_datasets = {'train': dataset.ImageDataset(df_train, transform=data_transforms['train']), \n",
    "                  'val': dataset.ImageDataset(df_test, transform=data_transforms['val'])}\n",
    "\n",
    "dataloaders = {'train': DataLoader(image_datasets['train'],batch_size=20,shuffle=True,num_workers=2),\n",
    "               'val' : DataLoader(image_datasets['val'],batch_size=20,shuffle=True,num_workers=2)}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for i,im in enumerate(dataloaders['train']):\n",
    "    for k in range(len(im[0])):\n",
    "        plt.imshow(im[0][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = model.FNet()\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 0.321 acc: 0.150\n",
      "[1,     6] loss: 1.613 acc: 0.200\n",
      "[1,    11] loss: 1.635 acc: 0.150\n",
      "[1,    16] loss: 1.609 acc: 0.200\n",
      "[1,    21] loss: 1.610 acc: 0.150\n",
      "[1,    26] loss: 1.594 acc: 0.100\n",
      "[1,    31] loss: 1.579 acc: 0.100\n",
      "[1,    36] loss: 1.602 acc: 0.400\n",
      "[1,    41] loss: 1.584 acc: 0.300\n",
      "[1,    46] loss: 1.576 acc: 0.200\n",
      "[1,    51] loss: 1.593 acc: 0.500\n",
      "[1,    56] loss: 1.582 acc: 0.400\n",
      "[1,    61] loss: 1.561 acc: 0.500\n",
      "[1,    66] loss: 1.516 acc: 0.300\n",
      "[1,    71] loss: 1.515 acc: 0.500\n",
      "[1,    76] loss: 1.517 acc: 0.500\n",
      "[1,    81] loss: 1.470 acc: 0.200\n",
      "[1,    86] loss: 1.433 acc: 0.250\n",
      "[1,    91] loss: 1.380 acc: 0.500\n",
      "[1,    96] loss: 1.341 acc: 0.650\n",
      "[2,     1] loss: 0.264 acc: 0.550\n",
      "[2,     6] loss: 1.313 acc: 0.350\n",
      "[2,    11] loss: 1.441 acc: 0.400\n",
      "[2,    16] loss: 1.184 acc: 0.550\n",
      "[2,    21] loss: 1.266 acc: 0.600\n",
      "[2,    26] loss: 1.284 acc: 0.550\n",
      "[2,    31] loss: 1.222 acc: 0.300\n",
      "[2,    36] loss: 1.268 acc: 0.600\n",
      "[2,    41] loss: 1.330 acc: 0.400\n",
      "[2,    46] loss: 1.335 acc: 0.500\n",
      "[2,    51] loss: 1.271 acc: 0.500\n",
      "[2,    56] loss: 1.286 acc: 0.300\n",
      "[2,    61] loss: 1.325 acc: 0.500\n",
      "[2,    66] loss: 1.272 acc: 0.400\n",
      "[2,    71] loss: 1.171 acc: 0.350\n",
      "[2,    76] loss: 1.261 acc: 0.450\n",
      "[2,    81] loss: 1.274 acc: 0.600\n",
      "[2,    86] loss: 1.221 acc: 0.650\n",
      "[2,    91] loss: 1.185 acc: 0.600\n",
      "[2,    96] loss: 1.106 acc: 0.500\n",
      "[3,     1] loss: 0.255 acc: 0.700\n",
      "[3,     6] loss: 1.128 acc: 0.650\n",
      "[3,    11] loss: 1.077 acc: 0.700\n",
      "[3,    16] loss: 1.043 acc: 0.750\n",
      "[3,    21] loss: 1.078 acc: 0.700\n",
      "[3,    26] loss: 1.003 acc: 0.700\n",
      "[3,    31] loss: 1.086 acc: 0.700\n",
      "[3,    36] loss: 0.937 acc: 0.650\n",
      "[3,    41] loss: 0.879 acc: 0.800\n",
      "[3,    46] loss: 1.012 acc: 0.850\n",
      "[3,    51] loss: 0.845 acc: 0.700\n",
      "[3,    56] loss: 1.016 acc: 0.500\n",
      "[3,    61] loss: 0.890 acc: 0.750\n",
      "[3,    66] loss: 0.956 acc: 0.750\n",
      "[3,    71] loss: 0.776 acc: 0.900\n",
      "[3,    76] loss: 1.006 acc: 0.800\n",
      "[3,    81] loss: 0.909 acc: 0.900\n",
      "[3,    86] loss: 0.895 acc: 0.750\n",
      "[3,    91] loss: 0.889 acc: 0.700\n",
      "[3,    96] loss: 0.892 acc: 0.850\n",
      "[4,     1] loss: 0.187 acc: 0.750\n",
      "[4,     6] loss: 0.789 acc: 0.950\n",
      "[4,    11] loss: 0.801 acc: 0.900\n",
      "[4,    16] loss: 0.715 acc: 0.800\n",
      "[4,    21] loss: 0.740 acc: 0.900\n",
      "[4,    26] loss: 0.682 acc: 0.950\n",
      "[4,    31] loss: 0.726 acc: 0.650\n",
      "[4,    36] loss: 0.585 acc: 0.950\n",
      "[4,    41] loss: 0.547 acc: 0.950\n",
      "[4,    46] loss: 0.512 acc: 0.850\n",
      "[4,    51] loss: 0.550 acc: 0.950\n",
      "[4,    56] loss: 0.503 acc: 1.000\n",
      "[4,    61] loss: 0.458 acc: 1.000\n",
      "[4,    66] loss: 0.385 acc: 0.850\n",
      "[4,    71] loss: 0.404 acc: 0.850\n",
      "[4,    76] loss: 0.316 acc: 1.000\n",
      "[4,    81] loss: 0.298 acc: 0.950\n",
      "[4,    86] loss: 0.343 acc: 1.000\n",
      "[4,    91] loss: 0.298 acc: 1.000\n",
      "[4,    96] loss: 0.270 acc: 0.850\n",
      "[5,     1] loss: 0.046 acc: 0.950\n",
      "[5,     6] loss: 0.236 acc: 0.900\n",
      "[5,    11] loss: 0.244 acc: 0.950\n",
      "[5,    16] loss: 0.192 acc: 1.000\n",
      "[5,    21] loss: 0.168 acc: 1.000\n",
      "[5,    26] loss: 0.139 acc: 1.000\n",
      "[5,    31] loss: 0.129 acc: 1.000\n",
      "[5,    36] loss: 0.116 acc: 0.950\n",
      "[5,    41] loss: 0.085 acc: 1.000\n",
      "[5,    46] loss: 0.078 acc: 1.000\n",
      "[5,    51] loss: 0.115 acc: 1.000\n",
      "[5,    56] loss: 0.061 acc: 1.000\n",
      "[5,    61] loss: 0.112 acc: 1.000\n",
      "[5,    66] loss: 0.058 acc: 1.000\n",
      "[5,    71] loss: 0.061 acc: 1.000\n",
      "[5,    76] loss: 0.049 acc: 1.000\n",
      "[5,    81] loss: 0.048 acc: 1.000\n",
      "[5,    86] loss: 0.060 acc: 1.000\n",
      "[5,    91] loss: 0.083 acc: 1.000\n",
      "[5,    96] loss: 0.064 acc: 1.000\n",
      "[6,     1] loss: 0.069 acc: 0.850\n",
      "[6,     6] loss: 0.101 acc: 1.000\n",
      "[6,    11] loss: 0.069 acc: 0.950\n",
      "[6,    16] loss: 0.086 acc: 1.000\n",
      "[6,    21] loss: 0.087 acc: 1.000\n",
      "[6,    26] loss: 0.069 acc: 0.900\n",
      "[6,    31] loss: 0.106 acc: 1.000\n",
      "[6,    36] loss: 0.023 acc: 1.000\n",
      "[6,    41] loss: 0.039 acc: 1.000\n",
      "[6,    46] loss: 0.054 acc: 1.000\n",
      "[6,    51] loss: 0.025 acc: 1.000\n",
      "[6,    56] loss: 0.034 acc: 1.000\n",
      "[6,    61] loss: 0.018 acc: 1.000\n",
      "[6,    66] loss: 0.011 acc: 1.000\n",
      "[6,    71] loss: 0.011 acc: 1.000\n",
      "[6,    76] loss: 0.012 acc: 1.000\n",
      "[6,    81] loss: 0.038 acc: 1.000\n",
      "[6,    86] loss: 0.026 acc: 1.000\n",
      "[6,    91] loss: 0.016 acc: 1.000\n",
      "[6,    96] loss: 0.010 acc: 1.000\n",
      "[7,     1] loss: 0.001 acc: 1.000\n",
      "[7,     6] loss: 0.016 acc: 1.000\n",
      "[7,    11] loss: 0.018 acc: 1.000\n",
      "[7,    16] loss: 0.005 acc: 1.000\n",
      "[7,    21] loss: 0.007 acc: 1.000\n",
      "[7,    26] loss: 0.009 acc: 1.000\n",
      "[7,    31] loss: 0.008 acc: 1.000\n",
      "[7,    36] loss: 0.006 acc: 1.000\n",
      "[7,    41] loss: 0.005 acc: 1.000\n",
      "[7,    46] loss: 0.020 acc: 0.950\n",
      "[7,    51] loss: 0.005 acc: 1.000\n",
      "[7,    56] loss: 0.007 acc: 1.000\n",
      "[7,    61] loss: 0.022 acc: 1.000\n",
      "[7,    66] loss: 0.007 acc: 1.000\n",
      "[7,    71] loss: 0.008 acc: 1.000\n",
      "[7,    76] loss: 0.021 acc: 1.000\n",
      "[7,    81] loss: 0.006 acc: 1.000\n",
      "[7,    86] loss: 0.012 acc: 1.000\n",
      "[7,    91] loss: 0.008 acc: 1.000\n",
      "[7,    96] loss: 0.005 acc: 1.000\n",
      "[8,     1] loss: 0.001 acc: 1.000\n",
      "[8,     6] loss: 0.004 acc: 1.000\n",
      "[8,    11] loss: 0.004 acc: 1.000\n",
      "[8,    16] loss: 0.013 acc: 1.000\n",
      "[8,    21] loss: 0.004 acc: 1.000\n",
      "[8,    26] loss: 0.007 acc: 1.000\n",
      "[8,    31] loss: 0.004 acc: 1.000\n",
      "[8,    36] loss: 0.006 acc: 1.000\n",
      "[8,    41] loss: 0.006 acc: 1.000\n",
      "[8,    46] loss: 0.004 acc: 1.000\n",
      "[8,    51] loss: 0.003 acc: 1.000\n",
      "[8,    56] loss: 0.013 acc: 1.000\n",
      "[8,    61] loss: 0.020 acc: 1.000\n",
      "[8,    66] loss: 0.006 acc: 1.000\n",
      "[8,    71] loss: 0.009 acc: 1.000\n",
      "[8,    76] loss: 0.005 acc: 1.000\n",
      "[8,    81] loss: 0.003 acc: 1.000\n",
      "[8,    86] loss: 0.006 acc: 1.000\n",
      "[8,    91] loss: 0.002 acc: 1.000\n",
      "[8,    96] loss: 0.003 acc: 1.000\n",
      "[9,     1] loss: 0.005 acc: 1.000\n",
      "[9,     6] loss: 0.002 acc: 1.000\n",
      "[9,    11] loss: 0.004 acc: 1.000\n",
      "[9,    16] loss: 0.002 acc: 1.000\n",
      "[9,    21] loss: 0.004 acc: 1.000\n",
      "[9,    26] loss: 0.005 acc: 1.000\n",
      "[9,    31] loss: 0.002 acc: 1.000\n",
      "[9,    36] loss: 0.007 acc: 1.000\n",
      "[9,    41] loss: 0.003 acc: 1.000\n",
      "[9,    46] loss: 0.002 acc: 1.000\n",
      "[9,    51] loss: 0.015 acc: 1.000\n",
      "[9,    56] loss: 0.002 acc: 1.000\n",
      "[9,    61] loss: 0.005 acc: 1.000\n",
      "[9,    66] loss: 0.002 acc: 1.000\n",
      "[9,    71] loss: 0.003 acc: 1.000\n",
      "[9,    76] loss: 0.002 acc: 1.000\n",
      "[9,    81] loss: 0.002 acc: 1.000\n",
      "[9,    86] loss: 0.003 acc: 1.000\n",
      "[9,    91] loss: 0.006 acc: 1.000\n",
      "[9,    96] loss: 0.002 acc: 1.000\n",
      "[10,     1] loss: 0.001 acc: 1.000\n",
      "[10,     6] loss: 0.004 acc: 1.000\n",
      "[10,    11] loss: 0.004 acc: 1.000\n",
      "[10,    16] loss: 0.003 acc: 1.000\n",
      "[10,    21] loss: 0.002 acc: 1.000\n",
      "[10,    26] loss: 0.004 acc: 1.000\n",
      "[10,    31] loss: 0.002 acc: 1.000\n",
      "[10,    36] loss: 0.005 acc: 1.000\n",
      "[10,    41] loss: 0.003 acc: 1.000\n",
      "[10,    46] loss: 0.004 acc: 1.000\n",
      "[10,    51] loss: 0.004 acc: 1.000\n",
      "[10,    56] loss: 0.003 acc: 1.000\n",
      "[10,    61] loss: 0.002 acc: 1.000\n",
      "[10,    66] loss: 0.003 acc: 1.000\n",
      "[10,    71] loss: 0.002 acc: 1.000\n",
      "[10,    76] loss: 0.002 acc: 1.000\n",
      "[10,    81] loss: 0.001 acc: 1.000\n",
      "[10,    86] loss: 0.002 acc: 1.000\n",
      "[10,    91] loss: 0.002 acc: 1.000\n",
      "[10,    96] loss: 0.002 acc: 1.000\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(dataloaders['train'], 0):\n",
    "    # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs = torch.transpose(inputs,3,1).float().to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 5 == 0:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f acc: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 5, \n",
    "                  (torch.sum(torch.argmax(outputs,1) == labels).float() / labels.size()[0]).item()))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,     1] loss: 0.000 acc: 0.200\n",
      "[2,     6] loss: 0.002 acc: 1.000\n",
      "[2,    11] loss: 0.003 acc: 1.000\n",
      "[2,    16] loss: 0.004 acc: 1.000\n",
      "[2,    21] loss: 0.005 acc: 1.000\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "losses = []\n",
    "epoch = 1\n",
    "running_loss = 0.0\n",
    "running_acc = 0.0\n",
    "for i, data in enumerate(dataloaders['val'], 0):\n",
    "    # get the inputs\n",
    "    inputs, labels = data\n",
    "    inputs = torch.transpose(inputs,3,1).float().to(device)\n",
    "    labels = labels.to(device)\n",
    "    outputs = net(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    acc = torch.sum(torch.argmax(outputs,1) == labels).float() / labels.size()[0]\n",
    "    accuracies.append(acc.item())\n",
    "    losses.append(loss.item())\n",
    "    running_loss += loss.item()\n",
    "    running_acc += acc.item()\n",
    "    if i % 5 == 0:    # print every 2000 mini-batches\n",
    "        print('[%d, %5d] loss: %.3f acc: %.3f' %\n",
    "              (epoch + 1, i + 1, running_loss / 5, running_acc / 5))\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
