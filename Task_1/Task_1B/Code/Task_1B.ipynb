{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1B: Fruit classification with a CNN\n",
    "\n",
    "This notebook will serve as implementation of the API that you have created in your \"Code\" folder. You will write functions in the \"py\" files and use them here.\n",
    "\n",
    "We will be using \"Fruits\" dataset present in PyTorch and train a convolutional neural network (CNN) to classify digits.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is expected from this notebook?\n",
    "\n",
    "This notebook should be used to present your work. You should explain wherever necessary (but also not too much) about what you did and why you did it. You should explain things like hyper parameter settings (even if it was provided before hand to you by us), training performance and testing performance of the model. You should reason why your model is working fine and not overfitting.\n",
    "\n",
    "Since numbers don't are an argot, you should also use visualizations wherever possible. You can visualize things like **loss curve**, show **confusion matrix** and since this is a CNN you can also consider **advance techniques like gradcam**, etc. \n",
    "\n",
    "You can also use techniques that allow for faster training, assuage problems involving vanishing and exploding gradients. \n",
    "\n",
    "Finally, you can show some manual verifications by displaying and making predictions on random test examples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Absolutely required items?\n",
    "\n",
    "1. First of all, import the libraries and the dataset. Divide the dataset into test and train.\n",
    "2. Next, show dataset samples and distribution of different type of data. For example, in case of \"Fruits Dataset\" you can show some random images and their labels. Also, show distribution of each class of images.\n",
    "3. Next, perform required transformations (also **data augmentation**) on \"Fruits dataset\" (normalization, resizing, grayscaling, if required, etc.) using torchvision transforms.\n",
    "4. Create required dataloaders with PyTorch and use the module dataset we created to load data in mini-batches.\n",
    "5. Train the model, show loss and accuracy at each step of operation.\n",
    "6. Plot the **loss curve for both train and validation phase**.\n",
    "7. Pick some manual random images (probably 7-10) from test dataset and predict their values showing **expected and actual result**. \n",
    "\n",
    "**NOTE: ** \n",
    "1. You may or may not choose to delete these instruction cells after completion of the notebook.\n",
    "2. Keep the outputs of the cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading dataframes using dataset module \n",
    "df, df_train, df_test = dataset.create_and_load_meta_csv_df(dataset_path='../Data/fruits/', destination_path='../Data/', randomize=True, split=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using dataframes, pytorch and torchvision to transform data. Also, use dataloaders for batching, shuffling, etc.  \n",
    "data_transforms = {\n",
    "    'train': [],\n",
    "    'val': []\n",
    "}\n",
    "\n",
    "image_datasets = {'train': dataset.ImageDataset(df_train, transform=data_transforms['train']), \n",
    "                  'val': dataset.ImageDataset(df_test, transform=data_transforms['val'])}\n",
    "\n",
    "dataloaders = {'train': DataLoader(image_datasets['train'],batch_size=20,shuffle=True,num_workers=2),\n",
    "               'val' : DataLoader(image_datasets['val'],batch_size=20,shuffle=True,num_workers=2)}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for i,im in enumerate(dataloaders['train']):\n",
    "    for k in range(len(im[0])):\n",
    "        plt.imshow(im[0][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = model.FNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 0.469\n",
      "[1,     6] loss: 2.334\n",
      "[1,    11] loss: 2.324\n",
      "[1,    16] loss: 2.315\n",
      "[1,    21] loss: 2.293\n",
      "[1,    26] loss: 2.267\n",
      "[1,    31] loss: 2.244\n",
      "[1,    36] loss: 2.238\n",
      "[1,    41] loss: 2.220\n",
      "[1,    46] loss: 2.183\n",
      "[1,    51] loss: 2.123\n",
      "[1,    56] loss: 2.074\n",
      "[1,    61] loss: 1.983\n",
      "[1,    66] loss: 1.994\n",
      "[1,    71] loss: 1.833\n",
      "[1,    76] loss: 1.780\n",
      "[1,    81] loss: 1.850\n",
      "[1,    86] loss: 1.677\n",
      "[1,    91] loss: 1.660\n",
      "[1,    96] loss: 1.668\n",
      "[2,     1] loss: 0.320\n",
      "[2,     6] loss: 1.465\n",
      "[2,    11] loss: 1.360\n",
      "[2,    16] loss: 1.230\n",
      "[2,    21] loss: 1.069\n",
      "[2,    26] loss: 1.031\n",
      "[2,    31] loss: 1.060\n",
      "[2,    36] loss: 0.951\n",
      "[2,    41] loss: 0.961\n",
      "[2,    46] loss: 0.771\n",
      "[2,    51] loss: 0.674\n",
      "[2,    56] loss: 0.762\n",
      "[2,    61] loss: 0.592\n",
      "[2,    66] loss: 0.584\n",
      "[2,    71] loss: 0.543\n",
      "[2,    76] loss: 0.490\n",
      "[2,    81] loss: 0.461\n",
      "[2,    86] loss: 0.399\n",
      "[2,    91] loss: 0.355\n",
      "[2,    96] loss: 0.284\n",
      "[3,     1] loss: 0.060\n",
      "[3,     6] loss: 0.198\n",
      "[3,    11] loss: 0.232\n",
      "[3,    16] loss: 0.192\n",
      "[3,    21] loss: 0.116\n",
      "[3,    26] loss: 0.129\n",
      "[3,    31] loss: 0.088\n",
      "[3,    36] loss: 0.103\n",
      "[3,    41] loss: 0.060\n",
      "[3,    46] loss: 0.091\n",
      "[3,    51] loss: 0.047\n",
      "[3,    56] loss: 0.074\n",
      "[3,    61] loss: 0.058\n",
      "[3,    66] loss: 0.159\n",
      "[3,    71] loss: 0.039\n",
      "[3,    76] loss: 0.062\n",
      "[3,    81] loss: 0.061\n",
      "[3,    86] loss: 0.036\n",
      "[3,    91] loss: 0.056\n",
      "[3,    96] loss: 0.027\n",
      "[4,     1] loss: 0.003\n",
      "[4,     6] loss: 0.078\n",
      "[4,    11] loss: 0.057\n",
      "[4,    16] loss: 0.049\n",
      "[4,    21] loss: 0.032\n",
      "[4,    26] loss: 0.029\n",
      "[4,    31] loss: 0.043\n",
      "[4,    36] loss: 0.023\n",
      "[4,    41] loss: 0.017\n",
      "[4,    46] loss: 0.027\n",
      "[4,    51] loss: 0.025\n",
      "[4,    56] loss: 0.007\n",
      "[4,    61] loss: 0.018\n",
      "[4,    66] loss: 0.021\n",
      "[4,    71] loss: 0.016\n",
      "[4,    76] loss: 0.009\n",
      "[4,    81] loss: 0.018\n",
      "[4,    86] loss: 0.035\n",
      "[4,    91] loss: 0.018\n",
      "[4,    96] loss: 0.020\n",
      "[5,     1] loss: 0.001\n",
      "[5,     6] loss: 0.012\n",
      "[5,    11] loss: 0.027\n",
      "[5,    16] loss: 0.008\n",
      "[5,    21] loss: 0.035\n",
      "[5,    26] loss: 0.035\n",
      "[5,    31] loss: 0.016\n",
      "[5,    36] loss: 0.010\n",
      "[5,    41] loss: 0.013\n",
      "[5,    46] loss: 0.017\n",
      "[5,    51] loss: 0.027\n",
      "[5,    56] loss: 0.009\n",
      "[5,    61] loss: 0.010\n",
      "[5,    66] loss: 0.012\n",
      "[5,    71] loss: 0.008\n",
      "[5,    76] loss: 0.015\n",
      "[5,    81] loss: 0.005\n",
      "[5,    86] loss: 0.004\n",
      "[5,    91] loss: 0.004\n",
      "[5,    96] loss: 0.003\n",
      "[6,     1] loss: 0.002\n",
      "[6,     6] loss: 0.009\n",
      "[6,    11] loss: 0.005\n",
      "[6,    16] loss: 0.005\n",
      "[6,    21] loss: 0.011\n",
      "[6,    26] loss: 0.006\n",
      "[6,    31] loss: 0.005\n",
      "[6,    36] loss: 0.005\n",
      "[6,    41] loss: 0.007\n",
      "[6,    46] loss: 0.004\n",
      "[6,    51] loss: 0.005\n",
      "[6,    56] loss: 0.003\n",
      "[6,    61] loss: 0.004\n",
      "[6,    66] loss: 0.016\n",
      "[6,    71] loss: 0.003\n",
      "[6,    76] loss: 0.020\n",
      "[6,    81] loss: 0.005\n",
      "[6,    86] loss: 0.004\n",
      "[6,    91] loss: 0.009\n",
      "[6,    96] loss: 0.011\n",
      "[7,     1] loss: 0.000\n",
      "[7,     6] loss: 0.005\n",
      "[7,    11] loss: 0.042\n",
      "[7,    16] loss: 0.005\n",
      "[7,    21] loss: 0.013\n",
      "[7,    26] loss: 0.003\n",
      "[7,    31] loss: 0.003\n",
      "[7,    36] loss: 0.013\n",
      "[7,    41] loss: 0.006\n",
      "[7,    46] loss: 0.005\n",
      "[7,    51] loss: 0.006\n",
      "[7,    56] loss: 0.004\n",
      "[7,    61] loss: 0.005\n",
      "[7,    66] loss: 0.005\n",
      "[7,    71] loss: 0.008\n",
      "[7,    76] loss: 0.005\n",
      "[7,    81] loss: 0.010\n",
      "[7,    86] loss: 0.003\n",
      "[7,    91] loss: 0.004\n",
      "[7,    96] loss: 0.003\n",
      "[8,     1] loss: 0.001\n",
      "[8,     6] loss: 0.002\n",
      "[8,    11] loss: 0.005\n",
      "[8,    16] loss: 0.003\n",
      "[8,    21] loss: 0.002\n",
      "[8,    26] loss: 0.002\n",
      "[8,    31] loss: 0.002\n",
      "[8,    36] loss: 0.005\n",
      "[8,    41] loss: 0.012\n",
      "[8,    46] loss: 0.005\n",
      "[8,    51] loss: 0.001\n",
      "[8,    56] loss: 0.004\n",
      "[8,    61] loss: 0.004\n",
      "[8,    66] loss: 0.005\n",
      "[8,    71] loss: 0.003\n",
      "[8,    76] loss: 0.003\n",
      "[8,    81] loss: 0.002\n",
      "[8,    86] loss: 0.005\n",
      "[8,    91] loss: 0.003\n",
      "[8,    96] loss: 0.003\n",
      "[9,     1] loss: 0.001\n",
      "[9,     6] loss: 0.005\n",
      "[9,    11] loss: 0.003\n",
      "[9,    16] loss: 0.002\n",
      "[9,    21] loss: 0.005\n",
      "[9,    26] loss: 0.002\n",
      "[9,    31] loss: 0.002\n",
      "[9,    36] loss: 0.002\n",
      "[9,    41] loss: 0.002\n",
      "[9,    46] loss: 0.012\n",
      "[9,    51] loss: 0.007\n",
      "[9,    56] loss: 0.007\n",
      "[9,    61] loss: 0.004\n",
      "[9,    66] loss: 0.001\n",
      "[9,    71] loss: 0.002\n",
      "[9,    76] loss: 0.011\n",
      "[9,    81] loss: 0.002\n",
      "[9,    86] loss: 0.004\n",
      "[9,    91] loss: 0.005\n",
      "[9,    96] loss: 0.002\n",
      "[10,     1] loss: 0.000\n",
      "[10,     6] loss: 0.001\n",
      "[10,    11] loss: 0.011\n",
      "[10,    16] loss: 0.008\n",
      "[10,    21] loss: 0.003\n",
      "[10,    26] loss: 0.003\n",
      "[10,    31] loss: 0.003\n",
      "[10,    36] loss: 0.008\n",
      "[10,    41] loss: 0.002\n",
      "[10,    46] loss: 0.002\n",
      "[10,    51] loss: 0.002\n",
      "[10,    56] loss: 0.004\n",
      "[10,    61] loss: 0.001\n",
      "[10,    66] loss: 0.014\n",
      "[10,    71] loss: 0.008\n",
      "[10,    76] loss: 0.002\n",
      "[10,    81] loss: 0.008\n",
      "[10,    86] loss: 0.002\n",
      "[10,    91] loss: 0.003\n",
      "[10,    96] loss: 0.002\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(dataloaders['train'], 0):\n",
    "    # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs = torch.transpose(inputs,3,1).float()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 5 == 0:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 5))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,     1] loss: 0.000\n",
      "[2,     6] loss: 0.003\n",
      "[2,    11] loss: 0.002\n",
      "[2,    16] loss: 0.006\n",
      "[2,    21] loss: 0.002\n"
     ]
    }
   ],
   "source": [
    "epoch = 1\n",
    "running_loss = 0.0\n",
    "for i, data in enumerate(dataloaders['val'], 0):\n",
    "    # get the inputs\n",
    "    inputs, labels = data\n",
    "    inputs = torch.transpose(inputs,3,1).float()\n",
    "    outputs = net(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    running_loss += loss.item()\n",
    "    if i % 5 == 0:    # print every 2000 mini-batches\n",
    "        print('[%d, %5d] loss: %.3f' %\n",
    "              (epoch + 1, i + 1, running_loss / 5))\n",
    "        running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
